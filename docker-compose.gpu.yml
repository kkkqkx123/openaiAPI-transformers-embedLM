version: '3.8'

services:
  emb-model-provider:
    build: 
      context: .
      dockerfile: Dockerfile.gpu
    container_name: emb-model-provider-gpu
    ports:
      - "9000:9000"
    volumes:
      # 挂载模型目录，避免重复下载
      - ./models:/models
      # 挂载日志目录（可选）
      - ./logs:/app/logs
    environment:
      # 模型配置
      - EMB_PROVIDER_MODEL_PATH=/models/multilingual-MiniLM-L12-v2
      - EMB_PROVIDER_MODEL_NAME=sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
      - EMB_PROVIDER_LOAD_FROM_TRANSFORMERS=false
      - EMB_PROVIDER_TRANSFORMERS_MODEL_NAME=sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
      - EMB_PROVIDER_TRANSFORMERS_TRUST_REMOTE_CODE=false
      
      # 处理配置
      - EMB_PROVIDER_MAX_BATCH_SIZE=64  # GPU可以处理更大的批次
      - EMB_PROVIDER_MAX_CONTEXT_LENGTH=512
      - EMB_PROVIDER_EMBEDDING_DIMENSION=384
      
      # 资源配置
      - EMB_PROVIDER_MEMORY_LIMIT=8GB  # GPU版本通常有更多内存
      - EMB_PROVIDER_DEVICE=cuda  # 使用GPU
      
      # API 配置
      - EMB_PROVIDER_HOST=0.0.0.0
      - EMB_PROVIDER_PORT=9000
      
      # 日志配置（容器环境默认禁用文件日志）
      - EMB_PROVIDER_LOG_LEVEL=INFO
      - EMB_PROVIDER_LOG_TO_FILE=false
      - EMB_PROVIDER_LOG_DIR=/app/logs
      - EMB_PROVIDER_LOG_FILE_MAX_SIZE=5
      - EMB_PROVIDER_LOG_RETENTION_DAYS=7
      - EMB_PROVIDER_LOG_CLEANUP_INTERVAL_HOURS=1
      - EMB_PROVIDER_LOG_MAX_DIR_SIZE_MB=10
      - EMB_PROVIDER_LOG_CLEANUP_TARGET_SIZE_MB=5
      - EMB_PROVIDER_LOG_CLEANUP_RETENTION_DAYS=7,3,1
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

volumes:
  prometheus_data:
  grafana_data:

networks:
  default:
    name: emb-model-provider-network