"""
å…¼å®¹æ€§æµ‹è¯•ï¼ŒéªŒè¯ä¸ OpenAI å®¢æˆ·ç«¯çš„å…¼å®¹æ€§
"""

import pytest
import json
from unittest.mock import patch, MagicMock
from fastapi.testclient import TestClient
from emb_model_provider.main import app
from emb_model_provider.core.config import config


@pytest.fixture
def client():
    """åˆ›å»ºæµ‹è¯•å®¢æˆ·ç«¯"""
    return TestClient(app)


class TestOpenAICompatibility:
    """OpenAI å®¢æˆ·ç«¯å…¼å®¹æ€§æµ‹è¯•"""
    
    def test_openai_python_client_format(self, client):
        """æµ‹è¯•ä¸ OpenAI Python å®¢æˆ·ç«¯çš„è¯·æ±‚æ ¼å¼å…¼å®¹æ€§"""
        # æ¨¡æ‹Ÿ OpenAI Python å®¢æˆ·ç«¯çš„è¯·æ±‚æ ¼å¼
        openai_format_request = {
            "input": "Test compatibility with OpenAI Python client",
            "model": "default",
            "encoding_format": "float",
            "user": "test-user-123"
        }
        
        response = client.post("/v1/embeddings", json=openai_format_request)
        assert response.status_code == 200
        
        # éªŒè¯å“åº”æ ¼å¼ç¬¦åˆ OpenAI API è§„èŒƒ
        data = response.json()
        
        # éªŒè¯é¡¶çº§å­—æ®µ
        assert "object" in data
        assert "data" in data
        assert "model" in data
        assert "usage" in data
        
        assert data["object"] == "list"
        assert data["model"] == "default"
        
        # éªŒè¯æ•°æ®å¯¹è±¡æ ¼å¼
        assert isinstance(data["data"], list)
        assert len(data["data"]) == 1
        
        embedding_object = data["data"][0]
        assert "object" in embedding_object
        assert "embedding" in embedding_object
        assert "index" in embedding_object
        
        assert embedding_object["object"] == "embedding"
        assert isinstance(embedding_object["embedding"], list)
        assert len(embedding_object["embedding"]) == config.embedding_dimension
        assert all(isinstance(x, (float, int)) for x in embedding_object["embedding"])
        assert embedding_object["index"] == 0
        
        # éªŒè¯ä½¿ç”¨æƒ…å†µå¯¹è±¡æ ¼å¼
        usage = data["usage"]
        assert "prompt_tokens" in usage
        assert "total_tokens" in usage
        assert isinstance(usage["prompt_tokens"], int)
        assert isinstance(usage["total_tokens"], int)
        assert usage["prompt_tokens"] > 0
        assert usage["total_tokens"] > 0
    
    def test_openai_batch_request_format(self, client):
        """æµ‹è¯•ä¸ OpenAI æ‰¹é‡è¯·æ±‚æ ¼å¼çš„å…¼å®¹æ€§"""
        # æ¨¡æ‹Ÿ OpenAI å®¢æˆ·ç«¯çš„æ‰¹é‡è¯·æ±‚æ ¼å¼
        batch_request = {
            "input": [
                "First test sentence for batch compatibility",
                "Second test sentence for batch compatibility",
                "Third test sentence for batch compatibility"
            ],
            "model": config.model_name,
            "encoding_format": "float"
        }
        
        response = client.post("/v1/embeddings", json=batch_request)
        assert response.status_code == 200
        
        data = response.json()
        
        # éªŒè¯æ‰¹é‡å“åº”æ ¼å¼
        assert data["object"] == "list"
        assert isinstance(data["data"], list)
        assert len(data["data"]) == 3
        
        # éªŒè¯æ¯ä¸ªåµŒå…¥å¯¹è±¡çš„ç´¢å¼•
        for i, embedding_object in enumerate(data["data"]):
            assert embedding_object["index"] == i
            assert embedding_object["object"] == "embedding"
            assert len(embedding_object["embedding"]) == config.embedding_dimension
        
        # éªŒè¯ä½¿ç”¨æƒ…å†µç»Ÿè®¡
        assert data["usage"]["prompt_tokens"] > 0
        assert data["usage"]["total_tokens"] > 0
    
    def test_openai_error_response_format(self, client):
        """æµ‹è¯•ä¸ OpenAI é”™è¯¯å“åº”æ ¼å¼çš„å…¼å®¹æ€§"""
        # æµ‹è¯•æ— æ•ˆè¯·æ±‚çš„é”™è¯¯å“åº”æ ¼å¼
        invalid_request = {
            "input": "",
            "model": config.model_name
        }
        
        response = client.post("/v1/embeddings", json=invalid_request)
        assert response.status_code == 400
        
        error_data = response.json()
        
        # éªŒè¯é”™è¯¯å“åº”æ ¼å¼ç¬¦åˆ OpenAI è§„èŒƒ
        assert "error" in error_data
        error = error_data["error"]
        
        assert "message" in error
        assert "type" in error
        assert "param" in error
        assert "code" in error or error["code"] is None
        
        assert error["type"] == "invalid_request_error"
        assert error["param"] == "input"
        assert "Input cannot be empty" in error["message"]
    
    def test_openai_models_endpoint_format(self, client):
        """æµ‹è¯•ä¸ OpenAI models ç«¯ç‚¹å“åº”æ ¼å¼çš„å…¼å®¹æ€§"""
        response = client.get("/v1/models")
        assert response.status_code == 200
        
        data = response.json()
        
        # éªŒè¯ models ç«¯ç‚¹å“åº”æ ¼å¼
        assert "object" in data
        assert "data" in data
        
        assert data["object"] == "list"
        assert isinstance(data["data"], list)
        assert len(data["data"]) >= 1
        
        # éªŒè¯æ¨¡å‹å¯¹è±¡æ ¼å¼
        model_object = data["data"][0]
        assert "id" in model_object
        assert "object" in model_object
        assert "created" in model_object
        assert "owned_by" in model_object
        
        assert model_object["object"] == "model"
        assert isinstance(model_object["created"], int)
        assert model_object["created"] > 0
    
    def test_openai_client_headers_compatibility(self, client):
        """æµ‹è¯•ä¸ OpenAI å®¢æˆ·ç«¯è¯·æ±‚å¤´çš„å…¼å®¹æ€§"""
        # æ¨¡æ‹Ÿ OpenAI å®¢æˆ·ç«¯å‘é€çš„è¯·æ±‚å¤´
        headers = {
            "Content-Type": "application/json",
            "Authorization": "Bearer sk-test-key",  # è™½ç„¶æˆ‘ä»¬ä¸éªŒè¯ï¼Œä½†åº”è¯¥æ¥å—
            "User-Agent": "OpenAI/Python/v1.0.0"
        }
        
        request_data = {
            "input": "Test header compatibility",
            "model": config.model_name
        }
        
        response = client.post("/v1/embeddings", json=request_data, headers=headers)
        assert response.status_code == 200
        
        # éªŒè¯å“åº”åŒ…å«é€‚å½“çš„å¤´
        assert "content-type" in response.headers
        assert response.headers["content-type"] == "application/json"
    
    def test_mock_openai_client_response_format(self, client):
        """æµ‹è¯• API å“åº”æ ¼å¼ä¸ OpenAI å®¢æˆ·ç«¯æœŸæœ›çš„ä¸€è‡´æ€§"""
        # é¢„æœŸçš„ OpenAI API å“åº”æ ¼å¼
        expected_response_format = {
            "object": "list",
            "data": [
                {
                    "object": "embedding",
                    "embedding": [0.1, 0.2, 0.3] + [0.0] * (config.embedding_dimension - 3),
                    "index": 0
                }
            ],
            "model": config.model_name,
            "usage": {
                "prompt_tokens": 5,
                "total_tokens": 5
            }
        }
        
        # è¿™é‡Œæˆ‘ä»¬æµ‹è¯•æˆ‘ä»¬çš„ API æ˜¯å¦èƒ½äº§ç”Ÿä¸ OpenAI å®¢æˆ·ç«¯æœŸæœ›çš„ç›¸åŒæ ¼å¼çš„å“åº”
        request_data = {
            "input": "Test mock OpenAI client",
            "model": config.model_name
        }
        
        response = client.post("/v1/embeddings", json=request_data)
        assert response.status_code == 200
        
        our_response = response.json()
        
        # éªŒè¯æˆ‘ä»¬çš„å“åº”ç»“æ„ä¸ OpenAI å®¢æˆ·ç«¯æœŸæœ›çš„ä¸€è‡´
        assert our_response["object"] == expected_response_format["object"]
        assert len(our_response["data"]) == len(expected_response_format["data"])
        assert our_response["model"] == expected_response_format["model"]
        assert "usage" in our_response
        
        # éªŒè¯æ•°æ®å¯¹è±¡ç»“æ„
        our_embedding = our_response["data"][0]
        expected_embedding = expected_response_format["data"][0]
        
        assert our_embedding["object"] == expected_embedding["object"]
        assert "embedding" in our_embedding
        assert "index" in our_embedding
        assert len(our_embedding["embedding"]) == config.embedding_dimension
    
    def test_openai_api_version_compatibility(self, client):
        """æµ‹è¯•ä¸ OpenAI API ç‰ˆæœ¬çš„å…¼å®¹æ€§"""
        # æµ‹è¯•å¸¦æœ‰ API ç‰ˆæœ¬å¤´çš„è¯·æ±‚
        headers = {
            "OpenAI-Organization": "org-test",
            "OpenAI-Project": "proj-test"
        }
        
        request_data = {
            "input": "Test API version compatibility",
            "model": config.model_name
        }
        
        response = client.post("/v1/embeddings", json=request_data, headers=headers)
        assert response.status_code == 200
        
        # éªŒè¯å“åº”æ ¼å¼
        data = response.json()
        assert "object" in data
        assert "data" in data
        assert "model" in data
        assert "usage" in data
    
    def test_openai_encoding_formats(self, client):
        """æµ‹è¯•ä¸åŒçš„ç¼–ç æ ¼å¼å…¼å®¹æ€§"""
        test_text = "Test encoding format compatibility"
        
        # æµ‹è¯• float æ ¼å¼ï¼ˆé»˜è®¤ï¼‰
        float_request = {
            "input": test_text,
            "model": config.model_name,
            "encoding_format": "float"
        }
        
        response = client.post("/v1/embeddings", json=float_request)
        assert response.status_code == 200
        
        data = response.json()
        embedding = data["data"][0]["embedding"]
        assert isinstance(embedding, list)
        assert all(isinstance(x, (float, int)) for x in embedding)
        
        # æ³¨æ„ï¼šæˆ‘ä»¬çš„å®ç°ç›®å‰ä¸æ”¯æŒ base64 æ ¼å¼ï¼Œä½†åº”è¯¥ä¼˜é›…åœ°å¤„ç†
        # è¿™é‡Œæˆ‘ä»¬æµ‹è¯•å¦‚æœå®¢æˆ·ç«¯è¯·æ±‚ base64 æ ¼å¼ä¼šå‘ç”Ÿä»€ä¹ˆ
        base64_request = {
            "input": test_text,
            "model": config.model_name,
            "encoding_format": "base64"
        }
        
        # æˆ‘ä»¬çš„å®ç°åº”è¯¥å¿½ç•¥ä¸æ”¯æŒçš„ç¼–ç æ ¼å¼å¹¶è¿”å›é»˜è®¤æ ¼å¼
        response = client.post("/v1/embeddings", json=base64_request)
        assert response.status_code == 200
        
        data = response.json()
        embedding = data["data"][0]["embedding"]
        assert isinstance(embedding, list)
        assert all(isinstance(x, (float, int)) for x in embedding)
    
    def test_openai_special_characters_handling(self, client):
        """æµ‹è¯•ç‰¹æ®Šå­—ç¬¦å¤„ç†çš„å…¼å®¹æ€§"""
        # æµ‹è¯•åŒ…å«ç‰¹æ®Šå­—ç¬¦çš„æ–‡æœ¬
        special_texts = [
            "Text with emoji ğŸš€ and symbols #$%",
            "Text with newlines\nand\ttabs",
            "Text with quotes: 'single' and \"double\"",
            "Text with unicode: ä¸­æ–‡, Ã±, Ã¼, Ã¸",
            "Text with math: âˆ‘âˆâˆ«âˆ†âˆ‡âˆ‚",
            "Text with currency: $â‚¬Â£Â¥â‚¹"
        ]
        
        for text in special_texts:
            request = {
                "input": text,
                "model": config.model_name
            }
            
            response = client.post("/v1/embeddings", json=request)
            assert response.status_code == 200
            
            data = response.json()
            assert len(data["data"][0]["embedding"]) == config.embedding_dimension
    
    def test_openai_large_request_handling(self, client):
        """æµ‹è¯•å¤§è¯·æ±‚å¤„ç†çš„å…¼å®¹æ€§"""
        # åˆ›å»ºä¸€ä¸ªè¾ƒå¤§çš„è¯·æ±‚ï¼Œä½†ä¸è¶…è¿‡é™åˆ¶
        large_text = "This is a test sentence. " * 50  # çº¦800ä¸ªå­—ç¬¦
        
        request = {
            "input": large_text,
            "model": config.model_name
        }
        
        response = client.post("/v1/embeddings", json=request)
        assert response.status_code == 200
        
        data = response.json()
        assert len(data["data"][0]["embedding"]) == config.embedding_dimension
        assert data["usage"]["prompt_tokens"] > 0
    
    def test_openai_response_time_consistency(self, client):
        """æµ‹è¯•å“åº”æ—¶é—´ä¸€è‡´æ€§"""
        test_text = "Test response time consistency"
        
        # å‘é€å¤šä¸ªç›¸åŒè¯·æ±‚ï¼ŒéªŒè¯å“åº”æ—¶é—´çš„ä¸€è‡´æ€§
        response_times = []
        for _ in range(5):
            request = {
                "input": test_text,
                "model": config.model_name
            }
            
            import time
            start_time = time.time()
            response = client.post("/v1/embeddings", json=request)
            end_time = time.time()
            
            assert response.status_code == 200
            response_times.append(end_time - start_time)
        
        # éªŒè¯å“åº”æ—¶é—´åœ¨åˆç†èŒƒå›´å†…æ³¢åŠ¨
        avg_time = sum(response_times) / len(response_times)
        max_deviation = max(abs(t - avg_time) for t in response_times)
        
        # å“åº”æ—¶é—´å˜åŒ–ä¸åº”å¤ªå¤§ï¼ˆè¿™é‡Œè®¾ç½®ä¸ºå¹³å‡æ—¶é—´çš„50%ï¼‰
        assert max_deviation < avg_time * 0.5, f"Response time variation too large: {max_deviation}s"


if __name__ == "__main__":
    pytest.main([__file__])